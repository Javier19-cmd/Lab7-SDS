{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "242a1ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.metrics import Precision, Recall, AUC\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9abb1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './malimg_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db7f53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9339 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "familias = ImageDataGenerator().flow_from_directory(directory=path, target_size=(64,64), batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "546b4119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'malimg_paper_dataset_imgs': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "familias.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "221f18f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(familias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90094adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9339, 64, 64, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795650de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9339, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4837c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots images with labels within jupyter notebook\n",
    "def plots(ims, figsize=(20,30), rows=10, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = 10 # len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(0,50):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(list(familias.class_indices.keys())[np.argmax(titles[i])], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3263a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plots(imgs, titles = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a2a5b1",
   "metadata": {},
   "source": [
    "### Primera parte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f4850b",
   "metadata": {},
   "source": [
    "Pre preprocesamiento adicional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e02504",
   "metadata": {},
   "source": [
    "Conteo de observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cf46da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9339 images belonging to 1 classes.\n",
      "Conteo de observaciones por familia de malware:\n",
      "malimg_paper_dataset_imgs: 9339\n"
     ]
    }
   ],
   "source": [
    "# Path al directorio con las imágenes\n",
    "path = './malimg_dataset/'\n",
    "\n",
    "# Crear un generador de datos con escalamiento de las imágenes\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Cargar imágenes desde el directorio\n",
    "generator = datagen.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "# Obtener las etiquetas de las clases del generador\n",
    "class_indices = generator.class_indices\n",
    "class_counts = {class_name: 0 for class_name in class_indices.keys()}\n",
    "\n",
    "# Contar el número de imágenes por clase\n",
    "for _, labels in generator:\n",
    "    for label in labels:\n",
    "        class_name = list(class_indices.keys())[np.argmax(label)]\n",
    "        class_counts[class_name] += 1\n",
    "    if generator.batch_index == 0:\n",
    "        break  # Romper el ciclo después de procesar todas las imágenes una vez\n",
    "\n",
    "# Mostrar el conteo de cada clase\n",
    "print(\"Conteo de observaciones por familia de malware:\")\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620b68ea",
   "metadata": {},
   "source": [
    "Dividiendo la data en 70% train y 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9dfa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "# Cargando todas las imágenes y etiquetas\n",
    "for _ in range(generator.samples // generator.batch_size + 1):\n",
    "    imgs, labels = next(generator)\n",
    "    all_images.append(imgs)\n",
    "    all_labels.append(labels)\n",
    "\n",
    "# Concatenando todas las imágenes y etiquetas en un solo array\n",
    "all_images = np.concatenate(all_images, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# Asegurándose de no tener más datos de los necesarios\n",
    "all_images = all_images[:generator.samples]\n",
    "all_labels = all_labels[:generator.samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86320630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.8941177  0.8941177  0.8941177 ]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.27058825 0.27058825 0.27058825]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   [0.00784314 0.00784314 0.00784314]]\n",
      "\n",
      "  [[0.27450982 0.27450982 0.27450982]\n",
      "   [0.14117648 0.14117648 0.14117648]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.2901961  0.2901961  0.2901961 ]\n",
      "   [0.05882353 0.05882353 0.05882353]\n",
      "   [0.01568628 0.01568628 0.01568628]]\n",
      "\n",
      "  [[0.5176471  0.5176471  0.5176471 ]\n",
      "   [0.92549026 0.92549026 0.92549026]\n",
      "   [0.35686275 0.35686275 0.35686275]\n",
      "   ...\n",
      "   [0.3137255  0.3137255  0.3137255 ]\n",
      "   [0.76470596 0.76470596 0.76470596]\n",
      "   [0.01568628 0.01568628 0.01568628]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7137255  0.7137255  0.7137255 ]\n",
      "   [0.8000001  0.8000001  0.8000001 ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.41176474 0.41176474 0.41176474]\n",
      "   [0.43921572 0.43921572 0.43921572]\n",
      "   [0.47450984 0.47450984 0.47450984]]\n",
      "\n",
      "  [[0.42352945 0.42352945 0.42352945]\n",
      "   [0.1254902  0.1254902  0.1254902 ]\n",
      "   [0.3803922  0.3803922  0.3803922 ]\n",
      "   ...\n",
      "   [0.3803922  0.3803922  0.3803922 ]\n",
      "   [0.454902   0.454902   0.454902  ]\n",
      "   [0.1254902  0.1254902  0.1254902 ]]\n",
      "\n",
      "  [[0.56078434 0.56078434 0.56078434]\n",
      "   [0.3529412  0.3529412  0.3529412 ]\n",
      "   [0.6039216  0.6039216  0.6039216 ]\n",
      "   ...\n",
      "   [0.01568628 0.01568628 0.01568628]\n",
      "   [0.37254903 0.37254903 0.37254903]\n",
      "   [0.8862746  0.8862746  0.8862746 ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.454902   0.454902   0.454902  ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.20000002 0.20000002 0.20000002]\n",
      "   [0.4039216  0.4039216  0.4039216 ]\n",
      "   [0.4901961  0.4901961  0.4901961 ]\n",
      "   ...\n",
      "   [0.14117648 0.14117648 0.14117648]\n",
      "   [0.16470589 0.16470589 0.16470589]\n",
      "   [0.43137258 0.43137258 0.43137258]]\n",
      "\n",
      "  [[0.0627451  0.0627451  0.0627451 ]\n",
      "   [0.60784316 0.60784316 0.60784316]\n",
      "   [0.5529412  0.5529412  0.5529412 ]\n",
      "   ...\n",
      "   [0.9725491  0.9725491  0.9725491 ]\n",
      "   [0.34901962 0.34901962 0.34901962]\n",
      "   [0.49803925 0.49803925 0.49803925]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.23529413 0.23529413 0.23529413]\n",
      "   [0.9333334  0.9333334  0.9333334 ]\n",
      "   [0.06666667 0.06666667 0.06666667]\n",
      "   ...\n",
      "   [0.5647059  0.5647059  0.5647059 ]\n",
      "   [0.8862746  0.8862746  0.8862746 ]\n",
      "   [0.6313726  0.6313726  0.6313726 ]]\n",
      "\n",
      "  [[0.92549026 0.92549026 0.92549026]\n",
      "   [0.9803922  0.9803922  0.9803922 ]\n",
      "   [0.227451   0.227451   0.227451  ]\n",
      "   ...\n",
      "   [0.9686275  0.9686275  0.9686275 ]\n",
      "   [0.6392157  0.6392157  0.6392157 ]\n",
      "   [0.09019608 0.09019608 0.09019608]]\n",
      "\n",
      "  [[0.63529414 0.63529414 0.63529414]\n",
      "   [0.3137255  0.3137255  0.3137255 ]\n",
      "   [0.13725491 0.13725491 0.13725491]\n",
      "   ...\n",
      "   [0.46274513 0.46274513 0.46274513]\n",
      "   [0.909804   0.909804   0.909804  ]\n",
      "   [0.9333334  0.9333334  0.9333334 ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.7411765  0.7411765  0.7411765 ]\n",
      "   [0.5647059  0.5647059  0.5647059 ]\n",
      "   [0.31764707 0.31764707 0.31764707]\n",
      "   ...\n",
      "   [0.72156864 0.72156864 0.72156864]\n",
      "   [0.16470589 0.16470589 0.16470589]\n",
      "   [0.3803922  0.3803922  0.3803922 ]]\n",
      "\n",
      "  [[0.0627451  0.0627451  0.0627451 ]\n",
      "   [0.54509807 0.54509807 0.54509807]\n",
      "   [0.5058824  0.5058824  0.5058824 ]\n",
      "   ...\n",
      "   [0.854902   0.854902   0.854902  ]\n",
      "   [0.8235295  0.8235295  0.8235295 ]\n",
      "   [0.32941177 0.32941177 0.32941177]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.25490198 0.25490198 0.25490198]\n",
      "   [0.76470596 0.76470596 0.76470596]\n",
      "   [0.27058825 0.27058825 0.27058825]\n",
      "   ...\n",
      "   [0.23137257 0.23137257 0.23137257]\n",
      "   [0.7411765  0.7411765  0.7411765 ]\n",
      "   [0.24705884 0.24705884 0.24705884]]\n",
      "\n",
      "  [[0.25490198 0.25490198 0.25490198]\n",
      "   [0.76470596 0.76470596 0.76470596]\n",
      "   [0.27058825 0.27058825 0.27058825]\n",
      "   ...\n",
      "   [0.23137257 0.23137257 0.23137257]\n",
      "   [0.7411765  0.7411765  0.7411765 ]\n",
      "   [0.24705884 0.24705884 0.24705884]]\n",
      "\n",
      "  [[0.7568628  0.7568628  0.7568628 ]\n",
      "   [0.2627451  0.2627451  0.2627451 ]\n",
      "   [0.7725491  0.7725491  0.7725491 ]\n",
      "   ...\n",
      "   [0.73333335 0.73333335 0.73333335]\n",
      "   [0.2392157  0.2392157  0.2392157 ]\n",
      "   [0.7490196  0.7490196  0.7490196 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.03137255 0.03137255 0.03137255]\n",
      "   ...\n",
      "   [0.7803922  0.7803922  0.7803922 ]\n",
      "   [0.7686275  0.7686275  0.7686275 ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.3803922  0.3803922  0.3803922 ]\n",
      "   [0.4901961  0.4901961  0.4901961 ]\n",
      "   [0.909804   0.909804   0.909804  ]\n",
      "   ...\n",
      "   [0.14509805 0.14509805 0.14509805]\n",
      "   [0.909804   0.909804   0.909804  ]\n",
      "   [0.27450982 0.27450982 0.27450982]]\n",
      "\n",
      "  [[0.8313726  0.8313726  0.8313726 ]\n",
      "   [0.2784314  0.2784314  0.2784314 ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.20784315 0.20784315 0.20784315]\n",
      "   [0.2784314  0.2784314  0.2784314 ]\n",
      "   [0.60784316 0.60784316 0.60784316]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3137255  0.3137255  0.3137255 ]\n",
      "   [0.07058824 0.07058824 0.07058824]\n",
      "   [0.09803922 0.09803922 0.09803922]\n",
      "   ...\n",
      "   [0.10196079 0.10196079 0.10196079]\n",
      "   [0.16862746 0.16862746 0.16862746]\n",
      "   [0.2392157  0.2392157  0.2392157 ]]\n",
      "\n",
      "  [[0.454902   0.454902   0.454902  ]\n",
      "   [0.4666667  0.4666667  0.4666667 ]\n",
      "   [0.1254902  0.1254902  0.1254902 ]\n",
      "   ...\n",
      "   [0.43137258 0.43137258 0.43137258]\n",
      "   [0.42352945 0.42352945 0.42352945]\n",
      "   [0.40784317 0.40784317 0.40784317]]\n",
      "\n",
      "  [[0.3803922  0.3803922  0.3803922 ]\n",
      "   [0.38431376 0.38431376 0.38431376]\n",
      "   [0.1254902  0.1254902  0.1254902 ]\n",
      "   ...\n",
      "   [0.31764707 0.31764707 0.31764707]\n",
      "   [0.39607847 0.39607847 0.39607847]\n",
      "   [0.39607847 0.39607847 0.39607847]]]\n",
      "\n",
      "\n",
      " [[[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.06666667 0.06666667 0.06666667]\n",
      "   [0.6156863  0.6156863  0.6156863 ]\n",
      "   [0.89019614 0.89019614 0.89019614]\n",
      "   ...\n",
      "   [0.6156863  0.6156863  0.6156863 ]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.48627454 0.48627454 0.48627454]]\n",
      "\n",
      "  [[0.43137258 0.43137258 0.43137258]\n",
      "   [0.47058827 0.47058827 0.47058827]\n",
      "   [0.27450982 0.27450982 0.27450982]\n",
      "   ...\n",
      "   [0.41176474 0.41176474 0.41176474]\n",
      "   [0.53333336 0.53333336 0.53333336]\n",
      "   [0.92549026 0.92549026 0.92549026]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5764706  0.5764706  0.5764706 ]\n",
      "   [0.58431375 0.58431375 0.58431375]\n",
      "   [0.86666673 0.86666673 0.86666673]\n",
      "   ...\n",
      "   [0.92549026 0.92549026 0.92549026]\n",
      "   [0.54509807 0.54509807 0.54509807]\n",
      "   [0.7686275  0.7686275  0.7686275 ]]\n",
      "\n",
      "  [[0.7019608  0.7019608  0.7019608 ]\n",
      "   [0.39607847 0.39607847 0.39607847]\n",
      "   [0.61960787 0.61960787 0.61960787]\n",
      "   ...\n",
      "   [0.59607846 0.59607846 0.59607846]\n",
      "   [0.37254903 0.37254903 0.37254903]\n",
      "   [0.1764706  0.1764706  0.1764706 ]]\n",
      "\n",
      "  [[0.2509804  0.2509804  0.2509804 ]\n",
      "   [0.56078434 0.56078434 0.56078434]\n",
      "   [0.7803922  0.7803922  0.7803922 ]\n",
      "   ...\n",
      "   [0.08235294 0.08235294 0.08235294]\n",
      "   [0.9568628  0.9568628  0.9568628 ]\n",
      "   [0.14117648 0.14117648 0.14117648]]]\n",
      "\n",
      "\n",
      " [[[0.3803922  0.3803922  0.3803922 ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.427451   0.427451   0.427451  ]\n",
      "   [0.13333334 0.13333334 0.13333334]\n",
      "   [0.03137255 0.03137255 0.03137255]\n",
      "   ...\n",
      "   [0.4901961  0.4901961  0.4901961 ]\n",
      "   [0.41176474 0.41176474 0.41176474]\n",
      "   [0.427451   0.427451   0.427451  ]]\n",
      "\n",
      "  [[0.98823535 0.98823535 0.98823535]\n",
      "   [0.33333334 0.33333334 0.33333334]\n",
      "   [0.98823535 0.98823535 0.98823535]\n",
      "   ...\n",
      "   [0.50980395 0.50980395 0.50980395]\n",
      "   [0.8862746  0.8862746  0.8862746 ]\n",
      "   [0.5137255  0.5137255  0.5137255 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6        0.6        0.6       ]\n",
      "   [0.882353   0.882353   0.882353  ]\n",
      "   [0.9215687  0.9215687  0.9215687 ]\n",
      "   ...\n",
      "   [0.5137255  0.5137255  0.5137255 ]\n",
      "   [0.1137255  0.1137255  0.1137255 ]\n",
      "   [0.8352942  0.8352942  0.8352942 ]]\n",
      "\n",
      "  [[0.2392157  0.2392157  0.2392157 ]\n",
      "   [0.227451   0.227451   0.227451  ]\n",
      "   [0.30980393 0.30980393 0.30980393]\n",
      "   ...\n",
      "   [0.8235295  0.8235295  0.8235295 ]\n",
      "   [0.35686275 0.35686275 0.35686275]\n",
      "   [0.24705884 0.24705884 0.24705884]]\n",
      "\n",
      "  [[0.94117653 0.94117653 0.94117653]\n",
      "   [0.36078432 0.36078432 0.36078432]\n",
      "   [0.86274517 0.86274517 0.86274517]\n",
      "   ...\n",
      "   [0.8000001  0.8000001  0.8000001 ]\n",
      "   [0.7137255  0.7137255  0.7137255 ]\n",
      "   [0.76470596 0.76470596 0.76470596]]]] [[[[0.00784314 0.00784314 0.00784314]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.3803922  0.3803922  0.3803922 ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.50980395 0.50980395 0.50980395]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.53333336 0.53333336 0.53333336]\n",
      "   ...\n",
      "   [0.3921569  0.3921569  0.3921569 ]\n",
      "   [0.9725491  0.9725491  0.9725491 ]\n",
      "   [0.34509805 0.34509805 0.34509805]]\n",
      "\n",
      "  [[0.6745098  0.6745098  0.6745098 ]\n",
      "   [0.4039216  0.4039216  0.4039216 ]\n",
      "   [0.07843138 0.07843138 0.07843138]\n",
      "   ...\n",
      "   [0.8117648  0.8117648  0.8117648 ]\n",
      "   [0.6156863  0.6156863  0.6156863 ]\n",
      "   [0.7294118  0.7294118  0.7294118 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.83921576 0.83921576 0.83921576]\n",
      "   [0.48235297 0.48235297 0.48235297]\n",
      "   [0.6901961  0.6901961  0.6901961 ]\n",
      "   ...\n",
      "   [0.9686275  0.9686275  0.9686275 ]\n",
      "   [0.07058824 0.07058824 0.07058824]\n",
      "   [0.17254902 0.17254902 0.17254902]]\n",
      "\n",
      "  [[0.49803925 0.49803925 0.49803925]\n",
      "   [0.01960784 0.01960784 0.01960784]\n",
      "   [0.45098042 0.45098042 0.45098042]\n",
      "   ...\n",
      "   [0.5803922  0.5803922  0.5803922 ]\n",
      "   [0.25882354 0.25882354 0.25882354]\n",
      "   [0.882353   0.882353   0.882353  ]]\n",
      "\n",
      "  [[0.47450984 0.47450984 0.47450984]\n",
      "   [0.7411765  0.7411765  0.7411765 ]\n",
      "   [0.69411767 0.69411767 0.69411767]\n",
      "   ...\n",
      "   [0.654902   0.654902   0.654902  ]\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.8588236  0.8588236  0.8588236 ]]]\n",
      "\n",
      "\n",
      " [[[0.8941177  0.8941177  0.8941177 ]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.27058825 0.27058825 0.27058825]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   [0.00784314 0.00784314 0.00784314]]\n",
      "\n",
      "  [[0.27450982 0.27450982 0.27450982]\n",
      "   [0.14117648 0.14117648 0.14117648]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.2901961  0.2901961  0.2901961 ]\n",
      "   [0.05882353 0.05882353 0.05882353]\n",
      "   [0.01568628 0.01568628 0.01568628]]\n",
      "\n",
      "  [[0.5176471  0.5176471  0.5176471 ]\n",
      "   [0.92549026 0.92549026 0.92549026]\n",
      "   [0.35686275 0.35686275 0.35686275]\n",
      "   ...\n",
      "   [0.3137255  0.3137255  0.3137255 ]\n",
      "   [0.76470596 0.76470596 0.76470596]\n",
      "   [0.01568628 0.01568628 0.01568628]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7137255  0.7137255  0.7137255 ]\n",
      "   [0.8000001  0.8000001  0.8000001 ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.41176474 0.41176474 0.41176474]\n",
      "   [0.43921572 0.43921572 0.43921572]\n",
      "   [0.47450984 0.47450984 0.47450984]]\n",
      "\n",
      "  [[0.42352945 0.42352945 0.42352945]\n",
      "   [0.1254902  0.1254902  0.1254902 ]\n",
      "   [0.3803922  0.3803922  0.3803922 ]\n",
      "   ...\n",
      "   [0.3803922  0.3803922  0.3803922 ]\n",
      "   [0.454902   0.454902   0.454902  ]\n",
      "   [0.1254902  0.1254902  0.1254902 ]]\n",
      "\n",
      "  [[0.56078434 0.56078434 0.56078434]\n",
      "   [0.3529412  0.3529412  0.3529412 ]\n",
      "   [0.6039216  0.6039216  0.6039216 ]\n",
      "   ...\n",
      "   [0.01568628 0.01568628 0.01568628]\n",
      "   [0.37254903 0.37254903 0.37254903]\n",
      "   [0.8862746  0.8862746  0.8862746 ]]]\n",
      "\n",
      "\n",
      " [[[0.05490196 0.05490196 0.05490196]\n",
      "   [0.12156864 0.12156864 0.12156864]\n",
      "   [0.7294118  0.7294118  0.7294118 ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.40784317 0.40784317 0.40784317]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.18823531 0.18823531 0.18823531]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.40784317 0.40784317 0.40784317]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.40000004 0.40000004 0.40000004]\n",
      "   [0.94117653 0.94117653 0.94117653]\n",
      "   [0.34901962 0.34901962 0.34901962]\n",
      "   ...\n",
      "   [0.09803922 0.09803922 0.09803922]\n",
      "   [0.52156866 0.52156866 0.52156866]\n",
      "   [0.627451   0.627451   0.627451  ]]\n",
      "\n",
      "  [[0.8588236  0.8588236  0.8588236 ]\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.97647065 0.97647065 0.97647065]\n",
      "   ...\n",
      "   [0.4784314  0.4784314  0.4784314 ]\n",
      "   [0.227451   0.227451   0.227451  ]\n",
      "   [0.81568635 0.81568635 0.81568635]]\n",
      "\n",
      "  [[0.6392157  0.6392157  0.6392157 ]\n",
      "   [0.21176472 0.21176472 0.21176472]\n",
      "   [0.98823535 0.98823535 0.98823535]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.00784314 0.00784314 0.00784314]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.3803922  0.3803922  0.3803922 ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.9921569  0.9921569  0.9921569 ]\n",
      "   [0.81568635 0.81568635 0.81568635]\n",
      "   [0.30980393 0.30980393 0.30980393]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.59607846 0.59607846 0.59607846]\n",
      "   [0.63529414 0.63529414 0.63529414]]\n",
      "\n",
      "  [[0.37254903 0.37254903 0.37254903]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.6039216  0.6039216  0.6039216 ]\n",
      "   ...\n",
      "   [0.882353   0.882353   0.882353  ]\n",
      "   [0.05882353 0.05882353 0.05882353]\n",
      "   [0.9803922  0.9803922  0.9803922 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7294118  0.7294118  0.7294118 ]\n",
      "   [0.8196079  0.8196079  0.8196079 ]\n",
      "   [0.07843138 0.07843138 0.07843138]\n",
      "   ...\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.32156864 0.32156864 0.32156864]\n",
      "   [0.86274517 0.86274517 0.86274517]]\n",
      "\n",
      "  [[0.02352941 0.02352941 0.02352941]\n",
      "   [0.49803925 0.49803925 0.49803925]\n",
      "   [0.10980393 0.10980393 0.10980393]\n",
      "   ...\n",
      "   [0.67058825 0.67058825 0.67058825]\n",
      "   [0.11764707 0.11764707 0.11764707]\n",
      "   [0.10980393 0.10980393 0.10980393]]\n",
      "\n",
      "  [[0.25882354 0.25882354 0.25882354]\n",
      "   [0.69803923 0.69803923 0.69803923]\n",
      "   [0.7568628  0.7568628  0.7568628 ]\n",
      "   ...\n",
      "   [0.04313726 0.04313726 0.04313726]\n",
      "   [0.12156864 0.12156864 0.12156864]\n",
      "   [0.91372555 0.91372555 0.91372555]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.18823531 0.18823531 0.18823531]\n",
      "   [0.75294125 0.75294125 0.75294125]\n",
      "   ...\n",
      "   [0.52156866 0.52156866 0.52156866]\n",
      "   [0.         0.         0.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04705883 0.04705883 0.04705883]\n",
      "   [0.59607846 0.59607846 0.59607846]\n",
      "   [0.64705884 0.64705884 0.64705884]\n",
      "   ...\n",
      "   [0.85098046 0.85098046 0.85098046]\n",
      "   [0.6901961  0.6901961  0.6901961 ]\n",
      "   [0.34901962 0.34901962 0.34901962]]\n",
      "\n",
      "  [[0.41960788 0.41960788 0.41960788]\n",
      "   [0.4666667  0.4666667  0.4666667 ]\n",
      "   [0.454902   0.454902   0.454902  ]\n",
      "   ...\n",
      "   [0.8862746  0.8862746  0.8862746 ]\n",
      "   [0.6509804  0.6509804  0.6509804 ]\n",
      "   [0.6313726  0.6313726  0.6313726 ]]\n",
      "\n",
      "  [[0.5254902  0.5254902  0.5254902 ]\n",
      "   [0.01960784 0.01960784 0.01960784]\n",
      "   [0.18823531 0.18823531 0.18823531]\n",
      "   ...\n",
      "   [0.45098042 0.45098042 0.45098042]\n",
      "   [0.36078432 0.36078432 0.36078432]\n",
      "   [0.76470596 0.76470596 0.76470596]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.454902   0.454902   0.454902  ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.54509807 0.54509807 0.54509807]\n",
      "   [0.29803923 0.29803923 0.29803923]\n",
      "   [0.227451   0.227451   0.227451  ]\n",
      "   ...\n",
      "   [0.40784317 0.40784317 0.40784317]\n",
      "   [0.93725497 0.93725497 0.93725497]\n",
      "   [0.83921576 0.83921576 0.83921576]]\n",
      "\n",
      "  [[0.7411765  0.7411765  0.7411765 ]\n",
      "   [0.28235295 0.28235295 0.28235295]\n",
      "   [0.4156863  0.4156863  0.4156863 ]\n",
      "   ...\n",
      "   [0.6392157  0.6392157  0.6392157 ]\n",
      "   [0.04705883 0.04705883 0.04705883]\n",
      "   [0.26666668 0.26666668 0.26666668]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6627451  0.6627451  0.6627451 ]\n",
      "   [0.6666667  0.6666667  0.6666667 ]\n",
      "   [0.4784314  0.4784314  0.4784314 ]\n",
      "   ...\n",
      "   [0.5882353  0.5882353  0.5882353 ]\n",
      "   [0.50980395 0.50980395 0.50980395]\n",
      "   [0.90196085 0.90196085 0.90196085]]\n",
      "\n",
      "  [[0.3254902  0.3254902  0.3254902 ]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.22352943 0.22352943 0.22352943]\n",
      "   ...\n",
      "   [0.4156863  0.4156863  0.4156863 ]\n",
      "   [0.36078432 0.36078432 0.36078432]\n",
      "   [0.14117648 0.14117648 0.14117648]]\n",
      "\n",
      "  [[0.654902   0.654902   0.654902  ]\n",
      "   [0.40000004 0.40000004 0.40000004]\n",
      "   [0.19607845 0.19607845 0.19607845]\n",
      "   ...\n",
      "   [0.35686275 0.35686275 0.35686275]\n",
      "   [0.03529412 0.03529412 0.03529412]\n",
      "   [0.8313726  0.8313726  0.8313726 ]]]]\n"
     ]
    }
   ],
   "source": [
    "# Dividiendo los datos en un conjunto de entrenamiento y otro de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cae6074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (6537, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fed806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=(64, 64, 3)),  \n",
    "        MaxPooling2D(pool_size=2),\n",
    "        BatchNormalization(),  # Batch Normalization después de la primera capa de convolución\n",
    "        Conv2D(64, kernel_size=3, activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=2),\n",
    "        BatchNormalization(),  # Batch Normalization después de la segunda capa de convolución\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\", \n",
    "              kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)),  \n",
    "        Dropout(0.9),  # Ajustando la tasa de dropout\n",
    "        Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    # Compilando el modelo con regularización L1 y L2\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7161c195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6537 samples\n",
      "Epoch 1/5\n",
      "6537/6537 [==============================] - 18s 3ms/sample - loss: 17.7326 - accuracy: 0.7679\n",
      "Epoch 2/5\n",
      "6537/6537 [==============================] - 17s 3ms/sample - loss: 12.1644 - accuracy: 0.9555\n",
      "Epoch 3/5\n",
      "6537/6537 [==============================] - 17s 3ms/sample - loss: 7.1419 - accuracy: 0.9720\n",
      "Epoch 4/5\n",
      "6537/6537 [==============================] - 16s 2ms/sample - loss: 3.7835 - accuracy: 0.9812\n",
      "Epoch 5/5\n",
      "6537/6537 [==============================] - 17s 3ms/sample - loss: 2.0509 - accuracy: 0.9861\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convertiendo las etiquetas a one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Creando el modelo\n",
    "model = create_model()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=256)\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a12cc",
   "metadata": {},
   "source": [
    "### Segunda parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2de65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adversarial-robustness-toolbox in c:\\users\\sebas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.17.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\sebas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from adversarial-robustness-toolbox) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\sebas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from adversarial-robustness-toolbox) (1.9.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in c:\\users\\sebas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from adversarial-robustness-toolbox) (1.4.1.post1)\n",
      "Requirement already satisfied: six in c:\\users\\sebas\\appdata\\roaming\\python\\python311\\site-packages (from adversarial-robustness-toolbox) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sebas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from adversarial-robustness-toolbox) (65.5.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sebas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from adversarial-robustness-toolbox) (4.64.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sebas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sebas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (3.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sebas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->adversarial-robustness-toolbox) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e2655c",
   "metadata": {},
   "source": [
    "Cargando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from art.estimators.classification import KerasClassifier\n",
    "\n",
    "# Desactivar la ejecución ansiosa\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Cargar el modelo\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# Envolver el modelo con ART\n",
    "classifier = KerasClassifier(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c0b77e",
   "metadata": {},
   "source": [
    "Ataque de evasión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c305c35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en datos normales: 100.00%\n",
      "Accuracy en datos de ataque FGSM: 10.85%\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "\n",
    "# Configurar el ataque FGSM\n",
    "attack_fgsm = FastGradientMethod(estimator=classifier, eps=0.1)  # eps controla la magnitud del ataque\n",
    "\n",
    "# Generar ejemplos de ataque\n",
    "x_test_adv = attack_fgsm.generate(x=X_test)  # Asume que X_test son tus datos de prueba\n",
    "\n",
    "# Evaluar el modelo en datos de prueba normales para comparar\n",
    "predictions_normal = classifier.predict(X_test)\n",
    "accuracy_normal = np.mean(np.argmax(predictions_normal, axis=1) == np.argmax(y_test, axis=1))\n",
    "print(f\"Accuracy en datos normales: {accuracy_normal * 100:.2f}%\")\n",
    "\n",
    "# Evaluar el modelo con los datos de ataque\n",
    "predictions = classifier.predict(x_test_adv)\n",
    "accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))\n",
    "print(f\"Accuracy en datos de ataque FGSM: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f669aa4b",
   "metadata": {},
   "source": [
    "**Explicación del ataque de evasión:**\n",
    "\n",
    "El código que se tiene en la celda pertenece a un ataque adversario usando el método de \"Fast Gradient Sign Method (FGSM) por medio de la librería ART (Adversarial Robustness Toolbox) en Python. Primero, importo la librería FGSM y configuro el modelo \"classifier\" a atacar y la magnitud del ataque (en este caso un eps de 0.1). Luego, se generan imágenes adversarias y se asignan a la variable \"x_test_adv\" modificando así las imágenes de prueba de la variable \"X_test\" con el objetivo de engañar al modelo.\n",
    "\n",
    "El modelo se evalúa primero en las imágenes originales de prueba para obtener una línea base de precisión (o sea el \"accuracy_normal\"), enseñando así como se desempeña el modelo en condiciones normales. Finalmente, se evalúa la precisión del modelo con las imágenes adversarias para ver como afecta el ataque FGSM a su rendimiento ayudando a entender la robustez del modelo ante ataques adversarios. Este proceso es altamente importante para la seguridad en modelos de aprendizaje automático, permitiendo así identificar y mejorar su resistencia frente a manipulaciones malintencionadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e08fe",
   "metadata": {},
   "source": [
    "Ataque de extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa03145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.extraction import CopycatCNN\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargando el modelo preentrenado (víctima)\n",
    "model_victim = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Envolviendo el modelo en un clasificador ART\n",
    "classifier_victim = KerasClassifier(model=model_victim, clip_values=(0, 1))\n",
    "\n",
    "thieved_model = create_model()\n",
    "\n",
    "# Envolviendo el thieved model con un clasificador de ART\n",
    "thieved_classifier = KerasClassifier(model=thieved_model, clip_values=(0, 1))\n",
    "\n",
    "X_data = np.random.rand(100, 64, 64, 3)  # 100 imágenes aleatorias como ejemplo\n",
    "\n",
    "# Configurando el ataque Copycat CNN\n",
    "attack = CopycatCNN(classifier=classifier_victim, batch_size_fit=32, batch_size_query=32, nb_epochs=10, nb_stolen=100)\n",
    "\n",
    "# Ejecutando el ataque para extraer un nuevo modelo\n",
    "thieved_classifier = attack.extract(x=X_data, thieved_classifier=thieved_classifier)\n",
    "\n",
    "# Realizando las predicciones\n",
    "predictions = thieved_classifier.predict(X_test)\n",
    "\n",
    "# Asumiendo que y_test está en formato one-hot y necesita ser convertido\n",
    "if len(y_test.shape) > 1:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Verificar y ajustar las predicciones si es necesario\n",
    "if len(predictions.shape) > 1:\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculando el accuracy del modelo víctima\n",
    "predictions_original = classifier_victim.predict(X_test)\n",
    "if len(predictions_original.shape) > 1:\n",
    "    predictions_original = np.argmax(predictions_original, axis=1)\n",
    "\n",
    "accuracy_original = np.mean(predictions_original == y_test)\n",
    "print(f\"Accuracy of the original model: {accuracy_original * 100:.2f}%\")\n",
    "\n",
    "# Calculando el accuracy del modelo atacante\n",
    "accuracy_thieved = np.mean(predictions == y_test)\n",
    "print(f\"Accuracy of the thieved model: {accuracy_thieved * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ddd52",
   "metadata": {},
   "source": [
    "**Explicación del ataque de extracción:**\n",
    "\n",
    "El código que se tiene para el ataque de extracción utiliza la técnica de Copycat CNN para robar la funcionalidad de un modelo preentrenado usando así la librería ART en Python. En un principio se importan las librerías necesarisa y se carga el modelo preentrenado, designado así como el modelo víctima. El modelo cargado se envuelve en un clasificador ART, configurando así sus valores de entrada entre 0 y 1. Luego, se crea un nuevo modelo, denominado thieved modelo, que también se envuelve en un clasificador ART. SE preparan 100 imágenes aleatorias de tamaño 64x64 en 3 canales (que en este caso es el color completo) para utilizarlas en el ataque. El ataque Copycat CNN se configura con parámetros como tamaño de lote y número de épocas, y luego se ejecuta usando el clasificador de la víctima y las imágenes aleatorias para entrenar el modelo thieved a imitar el comportamiento del modelo original.\n",
    "\n",
    "Posteriormente, se evalúan ambolos modelos (víctima y thieved) en un conjunto de prueba \"X_test\", ajustando las predicciones y los etiquetados para calcular la precsión de clasificación. Finalmente, se calcula y se compara la precisión del modelo original y del modelo thieved, enseñando así que tan efectivo fue el modelo thieved para imitar la funcionalidad del modelo víctima. Lo anterior es importante para el contexto de seguridad para entender y reducir los riesgos de ataques que buscan clonar la funcionalidad de modelos sensibles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
